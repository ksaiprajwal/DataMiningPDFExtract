
--- Page 1 ---
Mimir Pipeline: Github: https: github.com khushnaidu Mimir Data acquisition and processing: This will now be the key part. Instead of having specific queries for the Reddit API, we will just fetch as much data as we can from a list of political subreddits and embed the data into our vector DB. Usage: When the user highlights a large, complex text, it is sent to our backend. 1. We use language models for two separate tasks: a. Extract key components from the user s text and prepare them for the News API pipeline. b. Analyze and reformat the query (without losing context or adding any corrupting changes) and send it to the Reddit pipeline. 2. For the Reddit pipeline, we perform the notorious RAG requirement. This is when we take the query, embed it, and then perform a similarity search against our Reddit vector DB and fetch Reddit posts where the content has high similarity to the query. 3. Next, we use the News API pipeline to take the extracted components and format them in the most News API-compatible way to use them as search terms to query News API and fetch relevant news articles about them. 4. Next, we take both the data prepared by the Reddit pipeline and the data prepared by the News API pipeline and feed it to an LLM that can holistically describe the news context and popular discourse (based on Reddit) from it. This means that the final results will be such that instead of going the route of bias classification and complicating things, the user gets a large context summary of political discourse on Reddit across the spectrum as well as news articles in relation to the text they highlighted while they were scrolling Twitter, etc.

--- Page 2 ---
Data Acquisition Strategy Overview This system fetches political content from Reddit using a multi-faceted approach that combines recent posts and topic-based archival content. The strategy ensures both temporal diversity and comprehensive topic coverage for downstream applications like retrieval-augmented generation (RAG) and discourse analysis. Data Sources 1. Recent Posts (4,516 posts) Collected from 7 political subreddits: r politics r news r Conservative r neoliberal r moderatepolitics r Libertarian r socialism Post Types and Time Filters Top Posts (2,808 posts total) Day: 311 posts Week: 851 posts

--- Page 3 ---
Month: 559 posts Year: 2,070 posts All-time: 683 posts Controversial Posts (1,666 posts total) Past week: 100 posts per subreddit Past year: 200 posts per subreddit Current Posts (42 posts total) Hot: 5 posts Rising: 37 posts New: 37 posts 2. Archival Posts (5,292 posts) Keyword-based search across all subreddits for 12 key political topics: Topic Posts Keywords Foreign Policy 714 ukraine, nato, china, israel, gaza, taiwan Social Justice 604 racism, BLM, DEI, affirmative action, police brutality Healthcare 500 medicare, obamacare, health insurance, public option Gun Rights 494 guns, gun control, second amendment, NRA Immigration 482 immigration, border wall, asylum, ICE Abortion 385 abortion, roe v wade, planned parenthood Climate Change 387 climate change, global warming, green energy Elections 378 election fraud, ballot, voting machines Education 330 student loans, critical race theory, school choice Free Speech 328 censorship, twitter files, content moderation Taxes 328 income tax, capital gains, tax reform Technology AI 362 artificial intelligence, surveillance, facial recognition

--- Page 4 ---
Data Quality Metrics Temporal Coverage Date Range: January 4, 2009 May 9, 2025 Covers both historical and current discourse. Engagement Metrics Average Score: 9,702.22 Average Comments: 1,230.27 Reflects high engagement and discussion quality. Distribution Insights Posts per subreddit: 1,226 1,598 Posts per topic: 328 714 Corpus composition: 46 Recent 54 Archival Data Structure Each post includes: Metadata: ID, title, author, creation date Content: Selftext, URL, flair, permalink Engagement Metrics: Score, upvote ratio, comment count Top Comments: Top 5 by score, with metadata Classification Fields:

--- Page 5 ---
source: "recent" or "archive" topic: topic label for archival posts post_type: e.g. "top", "hot", "controversial" time_filter: e.g. "week", "month", "all" Technical Implementation Built with PRAW (Python Reddit API Wrapper) Implements: Deduplication via post ID Timeout handling and API rate-limit resilience Fetching Strategies: Multi-timeframe windowing (1d, 1w, 1m, 1y, all) Sort-based sampling (top, hot, rising, controversial, new) Topic keyword search with sort 'top', time_filter 'all' Post-processing includes comment hydration and engagement scoring Output Output File: reddit_political_posts_YYYYMMDD_HHMMSS.json Includes: Full posts array Structured metadata object for quick analysis Total Dataset Size: 9,808 unique posts

--- Page 6 ---
Remaining Implementation Plan Current Status Data acquisition and processing complete Embeddings generated and stored in app data embeddings Basic Flask application structure in place Initial components for query processing and vector store exist Implementation Tasks 1. Vector Store Enhancement File: app models vector_store.py import numpy as np import faiss import json from sentence_transformers import SentenceTransformer class VectorStore: def __init__(self, embeddings_path, metadata_path): self.embeddings np.load(embeddings_path) self.metadata json.load(open(metadata_path)) self.index faiss.IndexFlatL2(self.embeddings.shape[1]) self.index.add(self.embeddings) self.embedding_model SentenceTransformer('all-MiniLM-L6-v2') def search(self, query, k 5): query_embedding self.embedding_model.encode([query]) distances, indices self.index.search(query_embedding, k) return [(self.metadata[idx], distances[i]) for i, idx in enumerate(indices)] 2. LLM Pipeline Implementation

--- Page 7 ---
File: app utils llm_pipeline.py from transformers import AutoTokenizer, AutoModelForCausalLM import torch class LLMPipeline: def __init__(self): self.models 'mistral': self._load_model('mistralai Mistral-7B-Instruct-v0.2'), 'llama2': self._load_model('meta-llama Llama-2-7b-chat-hf'), 'falcon': self._load_model('tiiuae falcon-7b-instruct') def query_reformatter(self, text, model_name 'mistral'): prompt f"""Reformat the following text to be optimal for semantic search while preserving key concepts. Original text: text Reformatted query:""" return self._generate_response(self.models[model_name], prompt) def news_query_extractor(self, text, model_name 'mistral'): prompt f"""Extract key entities and topics from the following text that would be relevant for news search. Text: text Extracted components:""" return self._generate_response(self.models[model_name], prompt) def context_summarizer(self, context, model_name 'mistral'): prompt f"""Provide a comprehensive summary of the following context, highlighting different perspectives and key insights. Context: context Summary:""" return self._generate_response(self.models[model_name], prompt) 3. RAG Pipeline Implementation File: app utils rag_pipeline.py class RAGPipeline: def __init__(self, vector_store, llm_pipeline): self.vector_store vector_store self.llm_pipeline llm_pipeline async def process_query(self, user_text): reformatted_query self.llm_pipeline.query_reformatter(user_text) similar_posts self.vector_store.search(reformatted_query)

--- Page 8 ---
news_queries self.llm_pipeline.news_query_extractor(user_text) return 'similar_posts': similar_posts, 'news_queries': news_queries 4. News API Integration File: app utils news_api.py import aiohttp from typing import List, Dict class NewsAPIClient: def __init__(self, api_key: str): self.api_key api_key self.base_url "https: newsapi.org v2" async def search_news(self, queries: List[str]) - Dict: async with aiohttp.ClientSession() as session: results [] for query in queries: params 'q': query, 'apiKey': self.api_key, 'language': 'en', 'sortBy': 'relevancy', 'pageSize': 5 async with session.get(f" self.base_url everything", params params) as response: results.append(await response.json()) return results 5. Main Application Update File: app main.py from flask import Flask, request, jsonify from utils.llm_pipeline import LLMPipeline from utils.rag_pipeline import RAGPipeline from utils.news_api import NewsAPIClient from models.vector_store import VectorStore import os

--- Page 9 ---
from dotenv import load_dotenv app Flask(__name__) load_dotenv() vector_store VectorStore( "app data embeddings reddit_embeddings.npy", "app data embeddings embedding_metadata.json" ) llm_pipeline LLMPipeline() rag_pipeline RAGPipeline(vector_store, llm_pipeline) news_client NewsAPIClient(api_key os.getenv('NEWS_API_KEY')) app.route(' analyze', methods ['POST']) async def analyze_text(): data request.get_json() if not data or 'text' not in data: return jsonify( 'error': 'No text provided' ), 400 text data['text'] rag_results await rag_pipeline.process_query(text) news_results await news_client.search_news(rag_results['news_queries']) summaries for model_name in ['mistral', 'llama2', 'falcon']: context 'reddit_posts': rag_results['similar_posts'], 'news_articles': news_results summaries[model_name] llm_pipeline.context_summarizer( context, model_name model_name ) return jsonify( 'summaries': summaries, 'raw_context': 'reddit_posts': rag_results['similar_posts'], 'news_articles': news_results )

--- Page 10 ---
6. Evaluation Framework File: app utils evaluation.py t class ModelEvaluator: def __init__(self): self.metrics 'query_reformulation': [], 'news_extraction': [], 'summarization': [] def evaluate_models(self, test_cases): results for model_name in ['mistral', 'llama2', 'falcon']: results[model_name] self._evaluate_model(model_name, test_cases) return results def _evaluate_model(self, model_name, test_cases): metrics 'query_reformulation': self._evaluate_reformulation(model_name, test_cases), 'news_extraction': self._evaluate_extraction(model_name, test_cases), 'summarization': self._evaluate_summarization(model_name, test_cases) return metrics Implementation Order 1. Vector Store 2. LLM Pipeline 3. RAG Pipeline 4. News API Integration 5. Main Application 6. Evaluation Framework

--- Page 11 ---
Dependencies to Add Add these to requirements.txt: sentence-transformers 2.2.2 faiss-cpu 1.7.4 transformers 4.36.0 torch 2.1.0 aiohttp 3.9.0 python-dotenv 1.0.0 flask 3.0.0 Testing Requirements Unit tests for each class Integration tests for RAG API Performance benchmarks Model comparison metrics Documentation Requirements API docs ( analyze route) Setup instructions Model comparison results Performance metrics dashboard (optional) Class Requirements Coverage LLM Comparison: Mistral, Llama2, Falcon RAG Implementation: Full pipeline Few-shot Examples: Supported in evaluation

--- Page 12 ---
Model Evaluation: Custom metrics
